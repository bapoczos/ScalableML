{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEdwo9fM7_wf",
        "outputId": "3e893c59-912e-4f08-f451-cd6843705d64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar 21 20:52:07 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    27W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yEsi4ZWahHB",
        "outputId": "d2de11ff-066a-44a2-dbcd-59d0b61893b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.14.tar.gz (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (3.1.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from mako->pycuda) (2.1.2)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp39-cp39-linux_x86_64.whl size=661963 sha256=d422713ec672d215886272523322f41125ec5f9de54637fca15bf3480a7fdbca\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/09/27/74d8e31ed19c530166e0d263aabe1ea57465e255615bda8fc0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.14-py2.py3-none-any.whl size=69866 sha256=8886f239d23c6b7f0a910d96be8d84b167fa2dccb61f76a67a02008078d088d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/8c/332750bd78e80cdef14a96eb5b539adf0dcda50a97bbdfcbd8\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.2.4 pycuda-2022.2.2 pytools-2022.1.14\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test.py\n",
        "\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as drv\n",
        "from pycuda import gpuarray\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "ker = SourceModule('''\n",
        "__global__ void hello_world_ker()\n",
        "{\n",
        "\tprintf(\"Hello world from thread %d, in block %d!\\\\n\", threadIdx.x, blockIdx.x);\n",
        "\t\n",
        "\t__syncthreads();\n",
        "\t\n",
        "\tif(threadIdx.x == 0 && blockIdx.x == 0)\n",
        "\t{\n",
        "\t\tprintf(\"-------------------------------------\\\\n\");\n",
        "\t\tprintf(\"This kernel was launched over a grid consisting of %d blocks,\\\\n\", gridDim.x);\n",
        "\t\tprintf(\"where each block has %d threads.\\\\n\", blockDim.x);\n",
        "\t}\n",
        "}\n",
        "''')\n",
        "\n",
        "hello_ker = ker.get_function(\"hello_world_ker\")\n",
        "hello_ker(  block=(5,1,1), grid=(2,1,1) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3A7ZJfI7haZ",
        "outputId": "49848b77-5f6a-4066-9284-5ff28d955b8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKmAXCNL7pc_",
        "outputId": "a9300df3-9deb-4aec-c1fb-2f2d7e362dd4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world from thread 0, in block 1!\n",
            "Hello world from thread 1, in block 1!\n",
            "Hello world from thread 2, in block 1!\n",
            "Hello world from thread 3, in block 1!\n",
            "Hello world from thread 4, in block 1!\n",
            "Hello world from thread 0, in block 0!\n",
            "Hello world from thread 1, in block 0!\n",
            "Hello world from thread 2, in block 0!\n",
            "Hello world from thread 3, in block 0!\n",
            "Hello world from thread 4, in block 0!\n",
            "-------------------------------------\n",
            "This kernel was launched over a grid consisting of 2 blocks,\n",
            "where each block has 5 threads.\n"
          ]
        }
      ]
    }
  ]
}