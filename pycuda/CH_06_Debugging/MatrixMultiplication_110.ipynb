{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5hUe9SZDH1K",
        "outputId": "df623da4-eda4-4a4e-d5fd-66b3ad2128d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.14.tar.gz (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (3.1.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from mako->pycuda) (2.1.2)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp39-cp39-linux_x86_64.whl size=661963 sha256=97a37f77874bccaf7b0abe5f4ac571baa70e3f99f357f77914c55dfec06e90a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/09/27/74d8e31ed19c530166e0d263aabe1ea57465e255615bda8fc0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.14-py2.py3-none-any.whl size=69866 sha256=25679347ee3fcf228ffffc35ec5087d8936d060958c8ebdadab8ba2c72ecec1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/8c/332750bd78e80cdef14a96eb5b539adf0dcda50a97bbdfcbd8\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.2.4 pycuda-2022.2.2 pytools-2022.1.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as drv\n",
        "from pycuda import gpuarray\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "PC9ko2RCDWWM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oJjKENoMDEY9"
      },
      "outputs": [],
      "source": [
        "\n",
        "ker = SourceModule('''\n",
        "// row-column dot-product for matrix multiplication\n",
        "__device__ float rowcol_dot(float *matrix_a, float *matrix_b, int row, int col, int N)\n",
        "{\n",
        "\tfloat val = 0;\n",
        "\t\n",
        "\tfor (int k=0; k < N; k++)\n",
        "\t{\n",
        "        val += matrix_a[ row*N + k ] * matrix_b[ col + k*N];\n",
        "\t}\n",
        "\t\n",
        "\treturn(val);\n",
        "\n",
        "}\n",
        "\n",
        "// matrix multiplication kernel that is parallelized over row/column tuples.\n",
        "__global__ void matrix_mult_ker(float * matrix_a, float * matrix_b, float * output_matrix, int N)\n",
        "{\n",
        "\n",
        "    // for each (row,col) in the output_matrix, \n",
        "    // we calculate the entries of output_matrix parallel:\n",
        "    int row = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    int col = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "\n",
        "\toutput_matrix[col + row*N] = rowcol_dot(matrix_a, matrix_b, row, col, N);\n",
        "\n",
        "}\n",
        "''')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_ker = ker.get_function('matrix_mult_ker')\n"
      ],
      "metadata": {
        "id": "MgjXj5O3EEG6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_a = np.float32([np.arange(1,5)] * 4)\n",
        "test_b = np.float32([np.arange(14,10, -1)]*4 )\n"
      ],
      "metadata": {
        "id": "tSP-vom7EHwV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_a)\n",
        "print(test_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYW3rVg9EPTc",
        "outputId": "8d341932-4d74-4fa0-e4c9-2dae4e1cfd32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 2. 3. 4.]\n",
            " [1. 2. 3. 4.]\n",
            " [1. 2. 3. 4.]\n",
            " [1. 2. 3. 4.]]\n",
            "[[14. 13. 12. 11.]\n",
            " [14. 13. 12. 11.]\n",
            " [14. 13. 12. 11.]\n",
            " [14. 13. 12. 11.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_mat = np.matmul(test_a, test_b)\n",
        "print(output_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_4yk9JkEUyl",
        "outputId": "4bb1e534-4de7-4209-975f-e1a364a0fb99"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[140. 130. 120. 110.]\n",
            " [140. 130. 120. 110.]\n",
            " [140. 130. 120. 110.]\n",
            " [140. 130. 120. 110.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_a_gpu = gpuarray.to_gpu(test_a)\n",
        "test_b_gpu = gpuarray.to_gpu(test_b)\n",
        "output_mat_gpu = gpuarray.empty_like(test_a_gpu)\n"
      ],
      "metadata": {
        "id": "XgX2yjJbEZsh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_ker(test_a_gpu, test_b_gpu, output_mat_gpu, np.int32(4), block=(2,2,1), grid=(2,2,1))\n",
        "assert(np.allclose(output_mat_gpu.get(), output_mat) )\n",
        "\n"
      ],
      "metadata": {
        "id": "gNy3aJ3rEDE6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_mat_gpu.get())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FXMe9fFEhJi",
        "outputId": "19d39dfb-140d-462c-b43b-1a4198030732"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[140. 130. 120. 110.]\n",
            " [140. 130. 120. 110.]\n",
            " [140. 130. 120. 110.]\n",
            " [140. 130. 120. 110.]]\n"
          ]
        }
      ]
    }
  ]
}