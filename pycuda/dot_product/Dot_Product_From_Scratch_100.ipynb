{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Based on https://github.com/CodedK/CUDA-by-Example-source-code-for-the-book-s-examples-/blob/master/chapter05/dot.cu"
      ],
      "metadata": {
        "id": "_2usaJAV4n1-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "idY4hK011WhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba2c7ca-560a-415f-a16b-7ffa7ad5cf3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycuda\n",
            "  Downloading pycuda-2022.2.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.14.tar.gz (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (3.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.9/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from mako->pycuda) (2.1.2)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2022.2.2-cp39-cp39-linux_x86_64.whl size=661963 sha256=405576dcb34c5d04ce8d09dc7a14a40088c1c614390a2665cf29fb6d5ea3cd9a\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/09/27/74d8e31ed19c530166e0d263aabe1ea57465e255615bda8fc0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.14-py2.py3-none-any.whl size=69866 sha256=36298043d38eef51d55ffe42939480d481c0fd1264f440a614be9496b036a39c\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/8c/332750bd78e80cdef14a96eb5b539adf0dcda50a97bbdfcbd8\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.4 pycuda-2022.2.2 pytools-2022.1.14\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dot_prod.cu\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "\n",
        "const int threadsPerBlock = 1024; //must be a power of 2!\n",
        "\n",
        "extern \"C\" __global__ void dot_prod_ker(int dim, float *a, float *b, float *c )\n",
        "{\n",
        "  __shared__ float cache[threadsPerBlock];\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int cacheIndex = threadIdx.x;\n",
        "\n",
        "    float   temp = 0;\n",
        "    while (tid < dim) {\n",
        "        temp += a[tid] * b[tid];\n",
        "        tid += blockDim.x * gridDim.x;\n",
        "    }\n",
        "    \n",
        "    // set the cache values\n",
        "    cache[cacheIndex] = temp;\n",
        "    \n",
        "    // synchronize threads in this block\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction starts here!\n",
        "    // We have blockDim.x * gridDim.x num of threads, \n",
        "    // each containing a partial sum\n",
        "    \n",
        "    // for reductions, threadsPerBlock must be a power of 2\n",
        "    // because of the following code\n",
        "    int i = blockDim.x/2; //e.g 256/2\n",
        "    // Let us recursively sum the threads in the blocks\n",
        "    // The lower half gets the increade by the values from the upper half\n",
        "    while (i != 0) {\n",
        "        if (cacheIndex < i)\n",
        "            cache[cacheIndex] += cache[cacheIndex + i];\n",
        "        __syncthreads();\n",
        "        i /= 2;\n",
        "    }\n",
        "\n",
        "    if (cacheIndex == 0)\n",
        "        c[blockIdx.x] = cache[0];\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPujiwGG3_zv",
        "outputId": "1c7aa082-c707-42bf-ea8c-e79ec1b7212a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dot_prod.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -ptx -o dot_prod.ptx dot_prod.cu"
      ],
      "metadata": {
        "id": "BEhCFlCy5SaH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as drv\n",
        "from pycuda import gpuarray\n",
        "from pycuda.compiler import SourceModule\n",
        "from time import time\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Ck6WzylX6ErW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_mod = pycuda.driver.module_from_file('./dot_prod.ptx')\n",
        "dot_prod_ker = my_mod.get_function('dot_prod_ker')\n"
      ],
      "metadata": {
        "id": "WohoTJoK50hs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim=100000000\n",
        "\n",
        "threadsPerBlock = 1024; #this have to be a power of 2\n",
        "blocksPerGrid=32\n",
        "\n",
        "print(f'num of blocks: {blocksPerGrid}')\n",
        "print(f'num of threads in each block: {threadsPerBlock}')\n",
        "print(f'total number of threads in the grid: {blocksPerGrid*threadsPerBlock}')\n",
        "print(f'dim of vectors: {dim}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSUrpSH1LAIt",
        "outputId": "ad223fce-a519-482a-eaa2-0b284cd5c14d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num of blocks: 32\n",
            "num of threads in each block: 1024\n",
            "total number of threads in the grid: 32768\n",
            "dim of vectors: 100000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "veca=np.float32(np.random.randn(dim))\n",
        "#veca=np.float32(2.0*np.ones(dim))\n",
        "#vecb=np.float32(3.0*np.ones(dim))\n",
        "vecb=np.float32(np.random.randn(dim))\n",
        "\n",
        "vecc=np.float32(np.zeros(blocksPerGrid))\n",
        "\n",
        "veca_gpu=gpuarray.to_gpu(veca)\n",
        "vecb_gpu=gpuarray.to_gpu(vecb)\n",
        "vecc_gpu=gpuarray.to_gpu(vecc)\n",
        "\n",
        "print(len(veca), len(vecb), len(vecc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADG4jUi36ZM0",
        "outputId": "2e198c9a-9422-4f70-8407-277ca8005866"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000000 100000000 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=time()\n",
        "result=np.dot(veca,vecb)\n",
        "tCPU=time()-t\n",
        "print(f'dot product: {result}')\n",
        "print(f'Elapsed time on CPU: {tCPU}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9nmXd_P7mVa",
        "outputId": "4413a2d8-6e81-493f-be74-fc98bafa0e89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot product: 2319.245361328125\n",
            "Elapsed time on CPU: 0.06168532371520996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=time()\n",
        "dot_prod_ker(np.int32(dim), veca_gpu,vecb_gpu,vecc_gpu,grid=(blocksPerGrid, 1, 1), block=(threadsPerBlock,1,1))\n",
        "partial_sums_in_blocks=vecc_gpu.get()\n",
        "result=np.sum(partial_sums_in_blocks)\n",
        "tGPU=time()-t\n",
        "print(f'Elapsed time on GPU: {tGPU}')\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndixhj_r7Gck",
        "outputId": "473d40e5-4190-40b2-e4f3-fecd9c5104ad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time on GPU: 0.0033371448516845703\n",
            "2319.069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' GPU was {tCPU/tGPU} faster than CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl0RukGZQQh8",
        "outputId": "23bd9d3f-6d3d-4a83-a691-418d7dbd3b2b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " GPU was 18.484460955919126 faster than CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(partial_sums_in_blocks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttiCw22b9TTT",
        "outputId": "be56fa0e-54f3-496a-b764-6f73765fdb73"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1336.9792   -1993.2014   -2156.702     2223.04       182.18013\n",
            "  2755.8892    1312.0488    2456.3765    -328.09152   2733.114\n",
            " -2319.1826     930.0247    -879.2849    -553.6356    -559.4678\n",
            "  -333.90768    353.80548   1641.1185     877.84546     15.265015\n",
            " -3202.4907    -602.26465    290.2035    -907.8406      31.60608\n",
            "  -956.01434   3224.287     -129.60205    195.94568  -1124.1642\n",
            "  1882.0198   -1402.8711  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x6SRXIlgInZ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}