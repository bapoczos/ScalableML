{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from\n",
    "Fandango, Armando. Mastering TensorFlow 1.x: Advanced machine learning and deep learning concepts using TensorFlow 1.x and Keras (Kindle Locations 424-430). Packt Publishing. Kindle Edition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Get-an-Interactive-TensorFlow-Session\" data-toc-modified-id=\"Get-an-Interactive-TensorFlow-Session-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Get an Interactive TensorFlow Session</a></span></li><li><span><a href=\"#Customary-Hello-TensorFlow-!!!\" data-toc-modified-id=\"Customary-Hello-TensorFlow-!!!-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Customary Hello TensorFlow !!!</a></span></li><li><span><a href=\"#Constants\" data-toc-modified-id=\"Constants-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Constants</a></span></li><li><span><a href=\"#Operations\" data-toc-modified-id=\"Operations-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Operations</a></span></li><li><span><a href=\"#Placeholders\" data-toc-modified-id=\"Placeholders-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Placeholders</a></span></li><li><span><a href=\"#Creating-Tensors-from-Existing-Objects\" data-toc-modified-id=\"Creating-Tensors-from-Existing-Objects-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Creating Tensors from Existing Objects</a></span><ul class=\"toc-item\"><li><span><a href=\"#0-Dimensional-Tensors-(Scalars)\" data-toc-modified-id=\"0-Dimensional-Tensors-(Scalars)-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>0-Dimensional Tensors (Scalars)</a></span></li><li><span><a href=\"#1-Dimensional-Tensors-(Vectors)\" data-toc-modified-id=\"1-Dimensional-Tensors-(Vectors)-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>1-Dimensional Tensors (Vectors)</a></span></li><li><span><a href=\"#2-Dimensional-Tensors-(Matrices)\" data-toc-modified-id=\"2-Dimensional-Tensors-(Matrices)-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>2-Dimensional Tensors (Matrices)</a></span></li><li><span><a href=\"#3-Dimensional-Tensors\" data-toc-modified-id=\"3-Dimensional-Tensors-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>3-Dimensional Tensors</a></span></li></ul></li><li><span><a href=\"#Variables\" data-toc-modified-id=\"Variables-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Variables</a></span></li><li><span><a href=\"#Creating-Tensors-from-Library-Functions\" data-toc-modified-id=\"Creating-Tensors-from-Library-Functions-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Creating Tensors from Library Functions</a></span></li><li><span><a href=\"#Close-the-interactive-session\" data-toc-modified-id=\"Close-the-interactive-session-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Close the interactive session</a></span></li><li><span><a href=\"#Computation-Graphs\" data-toc-modified-id=\"Computation-Graphs-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Computation Graphs</a></span><ul class=\"toc-item\"><li><span><a href=\"#Building-and-Running-simple-computation-graph\" data-toc-modified-id=\"Building-and-Running-simple-computation-graph-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Building and Running simple computation graph</a></span></li><li><span><a href=\"#Graph-on-Compute-Devices\" data-toc-modified-id=\"Graph-on-Compute-Devices-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Graph on Compute Devices</a></span></li><li><span><a href=\"#Executing-Graph-g-as-Default\" data-toc-modified-id=\"Executing-Graph-g-as-Default-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>Executing Graph g as Default</a></span></li></ul></li><li><span><a href=\"#TensorBoard\" data-toc-modified-id=\"TensorBoard-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>TensorBoard</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 101 <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get an Interactive TensorFlow Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InteractiveSession becomes the default session\n",
    "tfs = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customary Hello TensorFlow !!!\n",
    "execute the constant in TF session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello TensorFlow !!'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant(\"Hello TensorFlow !!\")\n",
    "print(tfs.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can be created in the following ways: <br/>\n",
    "<br/>\n",
    "By defining constants, operations, and variables, and passing the values to their constructor. <br/>\n",
    "By defining placeholders and passing the values to session.run(). <br/>\n",
    "By converting Python objects such as scalar values, lists, and NumPy arrays with the tf.convert_to_tensor() function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1 (x):  Tensor(\"x:0\", shape=(), dtype=int32)\n",
      "c2 (y):  Tensor(\"y:0\", shape=(), dtype=float32)\n",
      "c3 (z):  Tensor(\"z:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c1 = tf.constant(5, name='x')\n",
    "c2 = tf.constant(6.0, name='y')\n",
    "c3 = tf.constant(7.0, tf.float32, name='z')\n",
    "print('c1 (x): ', c1)\n",
    "print('c2 (y): ', c2)\n",
    "print('c3 (z): ', c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to print the values of these constants, we have to execute them in a TensorFlow session with the tfs.run() command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run([c1,c2,c3]) :  [5, 6.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "print('run([c1,c2,c3]) : ', tfs.run([c1, c2, c3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Datatypes\n",
    "\n",
    "tf.float16 16-bit half-precision floating point <br/>\n",
    "tf.float32 32-bit single-precision floating point <br/>\n",
    "tf.float64 64-bit double-precision floating point <br/>\n",
    "tf.bfloat16 16-bit truncated floating point <br/>\n",
    "tf.complex64 64-bit single-precision complex <br/>\n",
    "tf.complex128 128-bit double-precision complex <br/>\n",
    "\n",
    "tf.int8 8-bit signed integer <br/>\n",
    "tf.uint8 8-bit unsigned integer  <br/>\n",
    "tf.uint16 16-bit unsigned integer <br/>\n",
    "tf.int16 16-bit signed integer <br/>\n",
    "tf.int32 32-bit signed integer <br/>\n",
    "tf.int64 64-bit signed integer <br/>\n",
    "\n",
    "tf.bool Boolean <br/>\n",
    "tf.string String <br/>\n",
    "tf.qint8 Quantized 8-bit signed integer <br/> \n",
    "tf.quint8 Quantized 8-bit unsigned integer <br/>\n",
    "tf.qint16 Quantized 16-bit signed integer <br/>\n",
    "tf.quint16 Quantized 16-bit unsigned integer <br/>\n",
    "tf.qint32 Quantized 32-bit signed integer <br/>\n",
    "tf.resource Handle to a mutable resource<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference between Session and Interactive Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference between Session() and InteractiveSession() is that the session created with InteractiveSession() becomes the default session. Thus, we do not need to specify the session context. For example, we have a session object, tfs, and a constant object, hello. If tfs is an InteractiveSession() object, then we can evaluate hello with the code hello.eval(). If tfs is a Session() object, then we have to use either tfs.hello.eval() or a with block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello = tf.constant(\"hi\",name=\"helloConstant\")\n",
    "hello.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1 = tf.add(c2, c3)\n",
    "op2 = tf.multiply(c2, c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we print op1 and op2, we find that they are defined as Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "op1 :  Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "op2 :  Tensor(\"Mul:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print('op1 : ', op1)\n",
    "print('op2 : ', op2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print the value of these operations, we have to run them in our TensorFlow session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run(op1) :  13.0\n",
      "run(op2) :  42.0\n"
     ]
    }
   ],
   "source": [
    "print('run(op1) : ', tfs.run(op1))\n",
    "print('run(op2) : ', tfs.run(op2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following table lists some of the built-in operations:\n",
    "\n",
    "Arithmetic operations: tf.add, tf.subtract, tf.multiply, tf.scalar_mul, tf.div, tf.divide, tf.truediv, tf.floordiv, tf.realdiv, tf.truncatediv, tf.floor_div, tf.truncatemod, tf.floormod, tf.mod, tf.cross <br/>\n",
    "<br/>\n",
    "Basic math operations: tf.add_n, tf.abs, tf.negative, tf.sign, tf.reciprocal, tf.square, tf.round, tf.sqrt, tf.rsqrt, tf.pow, tf.exp, tf.expm1, tf.log, tf.log1p, tf.ceil, tf.floor, tf.maximum, tf.minimum, tf.cos, tf.sin, tf.lbeta, tf.tan, tf.acos, tf.asin, tf.atan, tf.lgamma, tf.digamma, tf.erf, tf.erfc, tf.igamma, tf.squared_difference, tf.igammac, tf.zeta, tf.polygamma, tf.betainc, tf.rint<br/>\n",
    "<br/>\n",
    "Tensor math operations tf.tensordot <br/> \n",
    "<br/>\n",
    "Complex number operations tf.complex, tf.conj, tf.imag, tf.real <br/>\n",
    "<br/>\n",
    "String operations tf.string_to_hash_bucket_fast, tf.string_to_hash_bucket_strong, tf.as_string, tf.encode_base64, tf.decode_base64, tf.reduce_join, tf.string_join, tf.string_split, tf.substr, tf.string_to_hash_bucket\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders\n",
    "\n",
    "While constants allow us to provide a value at the time of defining the tensor, the placeholders allow us to create tensors whose values can be provided at runtime. TensorFlow provides the tf.placeholder() function with the following signature to create placeholders: \n",
    "<br/>\n",
    "<br/>\n",
    "tf.placeholder( dtype, shape = None, name = None)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 :  Tensor(\"Placeholder:0\", dtype=float32)\n",
      "p2 :  Tensor(\"Placeholder_1:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "p1 = tf.placeholder(tf.float32)\n",
    "p2 = tf.placeholder(tf.float32)\n",
    "print('p1 : ', p1)\n",
    "print('p2 : ', p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "op4 = p1 * p2  # shorthand for tf.multiply(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul_1:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(op4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run(op4,{p1:2.0, p2:3.0}) :  6.0\n"
     ]
    }
   ],
   "source": [
    "print('run(op4,{p1:2.0, p2:3.0}) : ',tfs.run(op4,{p1:2.0, p2:3.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify the dictionary using the feed_dict parameter in the run() operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run(op4,feed_dict = {p1:3.0, p2:4.0}) :  12.0\n"
     ]
    }
   ],
   "source": [
    "print('run(op4,feed_dict = {p1:3.0, p2:4.0}) : ',\n",
    "      tfs.run(op4, feed_dict={p1: 3.0, p2: 4.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run(op4,feed_dict={p1:[2.0,3.0,4.0], p2:[3.0,4.0,5.0]}): [ 6. 12. 20.]\n"
     ]
    }
   ],
   "source": [
    "print('run(op4,feed_dict={p1:[2.0,3.0,4.0], p2:[3.0,4.0,5.0]}):',\n",
    "      tfs.run(op4, feed_dict={p1: [2.0, 3.0, 4.0], p2: [3.0, 4.0, 5.0]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Tensors from Existing Objects\n",
    "We can create tensors from python objects such as lists and numpy arrays using the tf.convert_to_tensor() operation with the following signature: <br/>\n",
    "<br/>\n",
    "\n",
    "tf.convert_to_tensor( value, dtype = None, name = None, preferred_dtype = None )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-Dimensional Tensors (Scalars)\n",
    "Create and print a 0-D Tensor:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_t :  Tensor(\"Const_1:0\", shape=(), dtype=float64)\n",
      "run(tf_t) : \n",
      " 5.0\n"
     ]
    }
   ],
   "source": [
    "tf_t = tf.convert_to_tensor(5.0, dtype=tf.float64)\n",
    "\n",
    "print('tf_t : ', tf_t)\n",
    "print('run(tf_t) : \\n', tfs.run(tf_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Dimensional Tensors (Vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1dim Shape :  (5,)\n",
      "tf_t :  Tensor(\"Const_2:0\", shape=(5,), dtype=float64)\n",
      "tf_t[0] :  Tensor(\"strided_slice:0\", shape=(), dtype=float64)\n",
      "tf_t[2] :  Tensor(\"strided_slice_1:0\", shape=(), dtype=float64)\n",
      "run(tf_t) : \n",
      " [1.   2.   3.   4.   5.99]\n"
     ]
    }
   ],
   "source": [
    "a1dim = np.array([1, 2, 3, 4, 5.99])\n",
    "print(\"a1dim Shape : \", a1dim.shape)\n",
    "\n",
    "tf_t = tf.convert_to_tensor(a1dim, dtype=tf.float64)\n",
    "\n",
    "print('tf_t : ', tf_t)\n",
    "print('tf_t[0] : ', tf_t[0])\n",
    "print('tf_t[2] : ', tf_t[2])\n",
    "print('run(tf_t) : \\n', tfs.run(tf_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Dimensional Tensors (Matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2dim Shape :  (3, 5)\n",
      "tf_t :  Tensor(\"Const_3:0\", shape=(3, 5), dtype=float64)\n",
      "tf_t[0][0] :  Tensor(\"strided_slice_3:0\", shape=(), dtype=float64)\n",
      "tf_t[1][2] :  Tensor(\"strided_slice_5:0\", shape=(), dtype=float64)\n",
      "run(tf_t) : \n",
      " [[1.   2.   3.   4.   5.99]\n",
      " [2.   3.   4.   5.   6.99]\n",
      " [3.   4.   5.   6.   7.99]]\n"
     ]
    }
   ],
   "source": [
    "a2dim = np.array([(1, 2, 3, 4, 5.99),\n",
    "                  (2, 3, 4, 5, 6.99),\n",
    "                  (3, 4, 5, 6, 7.99)\n",
    "                  ])\n",
    "print(\"a2dim Shape : \", a2dim.shape)\n",
    "\n",
    "tf_t = tf.convert_to_tensor(a2dim, dtype=tf.float64)\n",
    "\n",
    "print('tf_t : ', tf_t)\n",
    "print('tf_t[0][0] : ', tf_t[0][0])\n",
    "print('tf_t[1][2] : ', tf_t[1][2])\n",
    "print('run(tf_t) : \\n', tfs.run(tf_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Dimensional Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3dim Shape :  (2, 2, 2)\n",
      "tf_t :  Tensor(\"Const_4:0\", shape=(2, 2, 2), dtype=float64)\n",
      "tf_t[0][0][0] :  Tensor(\"strided_slice_8:0\", shape=(), dtype=float64)\n",
      "tf_t[1][1][1] :  Tensor(\"strided_slice_11:0\", shape=(), dtype=float64)\n",
      "run(tf_t) : \n",
      " [[[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[5. 6.]\n",
      "  [7. 8.]]]\n"
     ]
    }
   ],
   "source": [
    "a3dim = np.array([[[1, 2],\n",
    "                   [3, 4]\n",
    "                   ],\n",
    "                  [[5, 6],\n",
    "                   [7, 8]\n",
    "                   ]\n",
    "                  ])\n",
    "print(\"a3dim Shape : \", a3dim.shape)\n",
    "\n",
    "tf_t = tf.convert_to_tensor(a3dim, dtype=tf.float64)\n",
    "\n",
    "print('tf_t : ', tf_t)\n",
    "print('tf_t[0][0][0] : ', tf_t[0][0][0])\n",
    "print('tf_t[1][1][1] : ', tf_t[1][1][1])\n",
    "print('run(tf_t) : \\n', tfs.run(tf_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables\n",
    "Variables are objects that can be updated during the executation of the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have seen how to create tensor objects of various kinds: constants, operations, and placeholders. <br/>\n",
    "<br/>\n",
    "While working with TensorFlow to build and train models, you will often need to hold the values of parameters in a memory location that can be updated at runtime. That memory location is identified by variables in TensorFlow.<br/> \n",
    "<br/>\n",
    "In TensorFlow, variables are tensor objects that hold values that can be modified during the execution of the program.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.placeholder defines input data that does not change over time <br/> \n",
    "tf.Variable defines variable values that are modified over time <br/>\n",
    "\n",
    "tf.placeholder does not need an initial value at the time of definition <br/>\n",
    "tf.Variable needs an initial value at the time of definition <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: <tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref>\n",
      "x: Tensor(\"Placeholder_2:0\", dtype=float32)\n",
      "b: <tf.Variable 'Variable_1:0' shape=(1,) dtype=float32_ref>\n",
      "y: Tensor(\"add_1:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Assume Linear Model y = w * x + b\n",
    "# Define model parameters\n",
    "w = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "# Define model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = w * x + b\n",
    "\n",
    "print(\"w:\", w)\n",
    "print(\"x:\", x)\n",
    "print(\"b:\", b)\n",
    "print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows that x is a placeholder tensor and y is an operation tensor, while w and b are variables with shape (1,) and data type float32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can use the variables in a TensorFlow session, they have to be initialized. <br/>\n",
    "You can initialize a single variable by running its initializer operation. For example, let's initialize the variable w: <br/>\n",
    "tfs.run( w.initializer) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs.run( w.initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in practice, we use a convenience function provided by the TensorFlow to initialize all the variables: <br/>tfs.run( tf.global_variables_initializer()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs.run( tf.global_variables_initializer()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use it outside of tfs.run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run(y,{x:[1,2,3,4]}) :  [0.         0.3        0.6        0.90000004]\n"
     ]
    }
   ],
   "source": [
    "# before using a variable, it has to be initialized\n",
    "# initialize and print the variable y\n",
    "tf.global_variables_initializer().run()\n",
    "print('run(y,{x:[1,2,3,4]}) : ', tfs.run(y, {x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the tf.variables_initializer() function to initialize only a set of variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Tensors from Library Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can also be generated from various TensorFlow functions. These generated tensors can either be assigned to a constant or a variable, or provided to their constructor at the time of initialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.zeros((100,))\n",
    "print(tfs.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zeros( shape, dtype = tf.float32, name = None ) Creates a tensor of the provided shape, with all elements set to zero <br/>\n",
    "<br/>\n",
    "zeros_like( tensor, dtype = None, name = None, optimize = True ) Creates a tensor of the same shape as the argument, with all elements set to zero <br/>\n",
    "<br/>\n",
    "ones( shape, dtype = tf.float32, name = None ) Creates a tensor of the provided shape, with all elements set to one <br/>\n",
    "<br/>\n",
    "ones_like( tensor, dtype = None, name = None, optimize = True ) Creates a tensor of the same shape as the argument, with all elements set to one <br/>\n",
    "<br/>\n",
    "fill( dims, value, name = None ) Creates a tensor of the shape as the dims argument, with all elements set to value;<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "a = tf.fill([100], 3) \n",
    "print(tfs.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating tensor elements with sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lin_space( start, stop, num, name = None ) Generates a 1-D tensor from a sequence of num numbers within the range [start, stop]. The tensor has the same data type as the start argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.  12.  23.  34.  45.  56.  67.  78.  89. 100.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.lin_space(1.0,100.0,10)\n",
    "print(tfs.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "range( limit, delta = 1, dtype = None, name =' range' ) <br/>\n",
    "range( start, limit, delta = 1, dtype = None, name =' range' ) <br/>\n",
    "<br/>\n",
    "Generates a 1-D tensor from a sequence of numbers within the range [start, limit], with the increments of delta. <br/>\n",
    "<br/>\n",
    "If the dtype argument is not specified, then the tensor has the same data type as the start argument. This function comes in two versions. In the second version, if the start argument is omitted, then start becomes number 0. <br/>\n",
    "<br/>\n",
    "For example, a = tf.range( 1,91,10) generates a tensor with values [1,11,21,31,41,51,61,71,81]. Note that the value of the limit argument, that is 91, is not included in the final generated sequence. <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 11 21 31 41 51 61 71 81]\n"
     ]
    }
   ],
   "source": [
    "a = tf.range( 1,91,10)\n",
    "print(tfs.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating tensor elements with a random distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow provides us with the functions to generate tensors filled with random valued distributions. <br/> \n",
    "\n",
    "The distributions generated are affected by the graph-level or the operation-level seed. <br/>\n",
    "\n",
    "The graph-level seed is set using tf.set_random_seed, while the operation-level seed is given as the argument seed in all of the random distribution functions. <br/>\n",
    "\n",
    "If no seed is specified, then a random seed is used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_normal( shape, mean = 0.0, stddev = 1.0, dtype = tf.float32, seed = None, name = None ) Generates a tensor of the specified shape, filled with values from a normal distribution: normal( mean, stddev).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "truncated_normal( shape, mean = 0.0, stddev = 1.0, dtype = tf.float32, seed = None, name = None ) Generates a tensor of the specified shape, filled with values from a truncated normal distribution: normal( mean, stddev). Truncated means that the values returned are always at a distance less than two standard deviations from the mean.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_uniform( shape, minval = 0, maxval = None, dtype = tf.float32, seed = None, name = None ) Generates a tensor of the specified shape, filled with values from a uniform distribution: uniform([ minval, maxval)). \n",
    "\n",
    "<br/>\n",
    "random_gamma( shape, alpha, beta = None, dtype = tf.float32, seed = None, name = None ) Generates tensors of the specified shape, filled with values from gamma distributions: gamma( alpha, beta).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_variable()\n",
    "\n",
    "If you define a variable with a name that has been defined before, then TensorFlow throws an exception. Hence, it is convenient to use the tf.get_variable() function instead of tf.Variable(). The function tf.get_variable() returns the existing variable with the same name if it exists, and creates the variable with the specified shape and initializer if it does not exist. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.get_variable( name ='w', dtype = tf.float32, initializer =[.3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.get_variable( name ='b', dtype = tf.float32, initializer =[-.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initializer can be a tensor or list of values as shown in above examples or one of the inbuilt initializers: <br/>\n",
    "<br/>\n",
    "tf.constant_initializer <br/>\n",
    "tf.random_normal_initializer <br/>\n",
    "tf.truncated_normal_initializer <br/>\n",
    "tf.random_uniform_initializer <br/>\n",
    "tf.uniform_unit_scaling_initializer <br/> \n",
    "tf.zeros_initializer <br/>\n",
    "tf.ones_initializer <br/>\n",
    "tf.orthogonal_initializer <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In distributed TensorFlow where we can run the code across machines, the tf.get_variable() gives us global variables. To get the local variables TensorFlow has a function with similar signature: tf.get_local_variable(). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharing or Reusing Variables: Getting already-defined variables promotes reuse. \n",
    "However, an exception will be thrown if the reuse flags are not set by using tf.variable_scope.reuse_variable() or tf.variable.scope( reuse = True).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Close the interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation graph is the basic unit of computation in TensorFlow. A computation graph is made up of nodes and edges. Each node represents an operation (tf.Operation) and each edge represents a tensor (tf.Tensor) that gets transferred between the nodes. <br/>\n",
    "\n",
    "You create the graph with nodes representing variables, constants, placeholders, and operations and feed it to TensorFlow. <br/>\n",
    "\n",
    "TensorFlow programs are made up of two kinds of operations on computation graphs: Building the computation graph Running the computation graph <br/>\n",
    "\n",
    "The TensorFlow comes with a default graph. Unless another graph is explicitly specified, a new node gets implicitly added to the default graph. We can get explicit access to the default graph using the following command: graph = tf.get_default_graph() <br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.framework.ops.Graph object at 0x7fb037d51358>\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Running simple computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output :  [0.         0.3        0.6        0.90000004]\n"
     ]
    }
   ],
   "source": [
    "# Assume Linear Model y = w * x + b\n",
    "# Define model parameters\n",
    "w = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "# Define model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = w * x + b\n",
    "output = 0\n",
    "\n",
    "with tf.Session() as tfs:\n",
    "    # initialize and print the variable y\n",
    "    tf.global_variables_initializer().run()\n",
    "    output = tfs.run(y, {x: [1, 2, 3, 4]})\n",
    "print('output : ', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and using a session in the with block ensures that the session is automatically closed when the block is finished. Otherwise, the session has to be explicitly closed with the tfs.close() command, where tfs is the session name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph on Compute Devices\n",
    "A graph can be divided into multiple parts, and each part can be placed and executed on seaparate devices such as cpu or gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15813908792753277838\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11280557671\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10173791928984445297\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# We can list all the devices available for graph executation\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default CPU: 0 denotes all the CPU's available to TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us enable the logging of variable placement by defining a config object, set the log_device_placement property to true, and then pass this config object to the session as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output [0.         0.3        0.6        0.90000004]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Define model parameters\n",
    "w = tf.get_variable(name='w', initializer=[.3], dtype=tf.float32)\n",
    "b = tf.get_variable(name='b', initializer=[-.3], dtype=tf.float32)\n",
    "# Define model input and output\n",
    "x = tf.placeholder(name='x', dtype=tf.float32)\n",
    "y = w * x + b\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "\n",
    "with tf.Session(config=config) as tfs:\n",
    "    # initialize and print the variable y\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    print('output', tfs.run(y, {x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This write this on the console\n",
    "Device mapping:  \n",
    "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7    \n",
    "w: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "w/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "w/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "b: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "b/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "b/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "add: (Add): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "init: (NoOp): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "w/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "Const_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "b/initial_value: (Const): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    "x: (Placeholder): /job:localhost/replica:0/task:0/device:GPU:0  \n",
    " \n",
    " \n",
    "Thus by default, the TensorFlow creates the variable and operations nodes on a device where it can get the highest performance. The variables and operations can be placed on specific devices by using tf.device() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output [0.         0.3        0.6        0.90000004]\n"
     ]
    }
   ],
   "source": [
    "# let us place the graph on the CPU instead of GPU\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device('/device:CPU:0'):\n",
    "    # Define model parameters\n",
    "    w = tf.get_variable(name='w', initializer=[.3], dtype=tf.float32)\n",
    "    b = tf.get_variable(name='b', initializer=[-.3], dtype=tf.float32)\n",
    "    # Define model input and output\n",
    "    x = tf.placeholder(name='x', dtype=tf.float32)\n",
    "    y = w * x + b\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "\n",
    "with tf.Session(config=config) as tfs:\n",
    "    # initialize and print the variable y\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    print('output', tfs.run(y, {x: [1, 2, 3, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device mapping:  \n",
    "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7  \n",
    "w: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "w/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "w/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "b: (VariableV2): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "b/Assign: (Assign): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "b/read: (Identity): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "mul: (Mul): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "add: (Add): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "init: (NoOp): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "Const: (Const): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "w/initial_value: (Const): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "Const_1: (Const): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "b/initial_value: (Const): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "x: (Placeholder): /job:localhost/replica:0/task:0/device:CPU:0  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow follows these simple rules, also known as the simple placement, for placing the variables on the devices:   \n",
    "\n",
    "If the graph was previously run, then the node is left on the device where it was placed earlier   \n",
    "Else If the tf.device() block is used, then the node is placed on the specified device    \n",
    "Else If the GPU is present then the node is placed on the first available GPU    \n",
    "Else If the GPU is not present then the node is placed on the CPU   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU memory handling \n",
    "\n",
    "When you start running the TensorFlow session, by default it grabs all of the GPU memory, even if you place the operations and variables only on one GPU in a multi-GPU system. \n",
    "\n",
    "If you try to run another session at the same time, you will get out of memory error.   \n",
    "\n",
    "This can be solved in multiple ways: For multi-GPU systems, set the environment variable   \n",
    "\n",
    "CUDA_VISIBLE_DEVICES = < list of device idx > os.environ[' CUDA_VISIBLE_DEVICES'] =' 0' \n",
    "\n",
    "The code executed after this setting will be able to grab all of the memory of only the visible GPU.   \n",
    "\n",
    "When you do not want the session to grab all of the memory of the GPU, then you can use the config option per_process_gpu_memory_fraction to allocate a percentage of memory:  \n",
    "\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5 \n",
    "\n",
    "This will allocate 50% of the memory of all the GPU devices. \n",
    "\n",
    "You can also combine both of the above strategies, i.e. make only a percentage along with making only some of the GPU visible to the process. \n",
    "\n",
    "You can also limit the TensorFlow process to grab only the minimum required memory at the start of the process. \n",
    "\n",
    "As the process executes further, you can set a config option to allow the growth of this memory. \n",
    "\n",
    "config.gpu_options.allow_growth = True \n",
    "\n",
    "This option only allows for the allocated memory to grow, but the memory is never released back.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Graph g as Default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple graphs You can create your own graphs separate from the default graph and execute them in a session. However, creating and executing multiple graphs is not recommended, as you cannot directly pass data in between graphs.  \n",
    "\n",
    "Hence, the recommended approach is to have multiple subgraphs in a single graph. \n",
    "\n",
    "In case you wish to use your own graph instead of the default graph, you can do so with the tf.graph() command. \n",
    "\n",
    "Here is an example where we create our own graph, g, and execute it as the default graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output :  [0.         0.3        0.6        0.90000004]\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "output = 0\n",
    "\n",
    "# Assume Linear Model y = w * x + b\n",
    "\n",
    "with g.as_default():\n",
    "    # Define model parameters\n",
    "    w = tf.Variable([.3], tf.float32)\n",
    "    b = tf.Variable([-.3], tf.float32)\n",
    "    # Define model input and output\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    y = w * x + b\n",
    "\n",
    "with tf.Session(graph=g) as tfs:\n",
    "    # initialize and print the variable y\n",
    "    tf.global_variables_initializer().run()\n",
    "    output = tfs.run(y, {x: [1, 2, 3, 4]})\n",
    "\n",
    "print('output : ', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Assume Linear Model y = w * x + b\n",
    "# Define model parameters\n",
    "w = tf.Variable([.3], name='w', dtype=tf.float32)\n",
    "b = tf.Variable([-.3], name='b', dtype=tf.float32)\n",
    "# Define model input and output\n",
    "x = tf.placeholder(name='x', dtype=tf.float32)\n",
    "y = w * x + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a session, and within the context of this session, do the following steps:  \n",
    "\n",
    "Initialize global variables   \n",
    "\n",
    "Create tf.summary.FileWriter that would create the output in the tflogs folder with the events from the default graph   \n",
    "\n",
    "Fetch the value of node y, effectively executing our linear model  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run(y,{x:3}) :  [0.6]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as tfs:\n",
    "    tf.global_variables_initializer().run()\n",
    "    writer = tf.summary.FileWriter('tflogs', tfs.graph)\n",
    "    print('run(y,{x:3}) : ', tfs.run(y, feed_dict={x: 3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute: tensorboard --logdir='tflogs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the program executes, the logs are collected in the tflogs folder that would be used by TensorBoard for visualization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the terminal start the environment that runs tensorflow, e.g.  \n",
    "\n",
    " source activate tensorflow_p36\n",
    "\n",
    "Go to the folder that has the log directory, e.g. ‘tflogs’ .  Then run\n",
    " tensorboard --logdir='tflogs'\n",
    "\n",
    "If you use AWS EC2: Open port 6006 (or the port you assigned to the visualization web server) on your EC2 instance.\n",
    "\n",
    "In the Amazon EC2 console, choose Network & Security, then choose Security Groups.  \n",
    "For Security Group, choose the one that was used for your instance. Choose the Inbound tab, and choose Edit.\n",
    "\n",
    "Choose Add Rule.\n",
    "\n",
    "In the new row, type the followings:\n",
    "\n",
    "Type : Custom TCP Rule  \n",
    "Protocol: TCP  \n",
    "Port Range: 6006 (or the port that you assigned to the visualization server)  \n",
    "Source: Anywhere (0.0.0.0/0,::/0)  \n",
    "\n",
    "To open the web page for the TensorBoard visualizations use the public IP or DNS address of the EC2 instance and the port that you opened for TensorBoard: http:// YourInstancePublicDNS:6006\n",
    "\n",
    "For example:  http://ec2-18-188-214-178.us-east-2.compute.amazonaws.com:6006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard works by reading log files generated by TensorFlow. Thus, we need to modify the programming model defined here to incorporate additional operation nodes that would produce the information in the logs that we want to visualize using TensorBoard.\n",
    "\n",
    "Create summary nodes. Attach summary operations from the tf.summary package to the nodes that output the values that you wish to collect and analyze. Run the summary nodes along with running your model nodes.\n",
    "\n",
    "Generally, you would use the convenience function, tf.summary.merge_all(), to merge all the summary nodes into one summary node. Then executing this merged node would basically execute all the summary nodes.\n",
    "\n",
    "The merged summary node produces a serialized Summary ProtocolBuffers object containing the union of all the summaries. Write the event logs to disk by passing the Summary ProtocolBuffers object to a tf.summary.FileWriter object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {
    "height": "306px",
    "width": "240px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
