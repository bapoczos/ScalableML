{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "from aio_pika import connect,IncomingMessage, Message, DeliveryMode, Exchange, ExchangeType\n",
    "import numpy as np\n",
    "import uuid\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_workers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=160\n",
    "n_clusters=3\n",
    "n_features =2\n",
    "\n",
    "np.random.seed(seed=1023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs, Ys = make_blobs(n_samples=n_samples, n_features=n_features, centers=n_clusters, shuffle =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "[7.4123751  1.65861249] 0\n"
     ]
    }
   ],
   "source": [
    "mydata= [{\"points\": x, \"label\": y} for x,y in zip(Xs,Ys)]\n",
    "print(len(mydata))\n",
    "print(mydata[15]['points'],mydata[15]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# Split the sequence in a number of chunks and process those independently.\n",
    "\n",
    "if 1:\n",
    "    l = n_samples // num_of_workers\n",
    "    Xsubseqs = [mydata[i * l:(i + 1) * l] for i in range(num_of_workers - 1)]\n",
    "    Xsubseqs.append(mydata[(num_of_workers - 1) * l:])\n",
    "else:\n",
    "    splitting_points=[100,300,1000]\n",
    "    Xsubseqs=[]\n",
    "    Xsubseqs.append(mydata[0:splitting_points[0]])\n",
    "    Xsubseqs.append(mydata[splitting_points[0]:splitting_points[1]])\n",
    "    Xsubseqs.append(mydata[splitting_points[1]:splitting_points[2]])\n",
    "    Xsubseqs.append(mydata[splitting_points[2]:])\n",
    "    \n",
    "for i in range(len(Xsubseqs)):\n",
    "    print(len(Xsubseqs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Centroids\n",
      "[[5.40267431 2.5528196 ]\n",
      " [0.28327334 4.37845997]\n",
      " [5.06196805 3.70517079]]\n"
     ]
    }
   ],
   "source": [
    "C=np.matrix(np.random.rand(n_clusters,n_features))*np.matrix(np.diag(np.max(Xs,0)))\n",
    "print(\"Initial Centroids\")\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    %matplotlib inline\n",
    "    plt.rcParams['figure.figsize'] = (8, 5)\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # Plotting along with the Centroids\n",
    "    #plt.scatter([actdata.points[0] for actdata in mydata], [actdata.points[1] for actdata in mydata])\n",
    "    plt.scatter([actdata['points'][0] for actdata in mydata], [actdata['points'][1] for actdata in mydata],c=[actdata['label'] for actdata in mydata], s=7)\n",
    "\n",
    "    plt.scatter(np.array(C[:,0]), np.array(C[:,1]), marker='*', s=200, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[5.40267431, 2.5528196 ],\n",
       "        [0.28327334, 4.37845997],\n",
       "        [5.06196805, 3.70517079]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RpcClient:\n",
    "    def __init__(self, num_of_workers, loop):\n",
    "        \n",
    "        self.connection = None #This will be filled-up later\n",
    "        self.channel = None #This will be filled-up later\n",
    "        self.callback_queue = None #This will be filled-up later\n",
    "        \n",
    "        self.loop = loop # This will contain an event loop\n",
    "        \n",
    "        # This is a dictionary. \n",
    "        # The key will be a correlation_id that we create when we call a worker machine.\n",
    "        # The value will be an asyncio.Future object.\n",
    "        self.futures = {}\n",
    "        self.datafutures = {}\n",
    "        self.w2s_queue_names=[]\n",
    "        \n",
    "        self.num_on_response_calls = 0 #We will count how many times workers responded to us\n",
    "        self.num_on_data2workers_calls=0\n",
    "        \n",
    "        self.num_of_workers = num_of_workers # We want two workers to respond to messages with 'Pittsburgh' routing\n",
    "        self.set_of_workers=set()\n",
    "        \n",
    "        #self.tr_data = tr_data\n",
    "        self.C = None\n",
    "        \n",
    "    async def connect(self):\n",
    "        \n",
    "        # Create a connection\n",
    "        self.connection = await connect(\n",
    "            \"amqp://guest:guest@localhost/\", loop=loop\n",
    "        )\n",
    "        \n",
    "        # Create a channel\n",
    "        self.channel = await self.connection.channel()\n",
    "        \n",
    "        # Create an exchange with type direct\n",
    "        self.exchange = await self.channel.declare_exchange('direct_logs', ExchangeType.DIRECT)\n",
    "\n",
    "        # Create a queue with random name \"self.callback_queue\" for receving messages from the workers\n",
    "        self.callback_queue = await self.channel.declare_queue('get_workers_w2s',exclusive=True)\n",
    "                \n",
    "                \n",
    "        # Start consuming messages on the \"self.callback_queue\" queue\n",
    "        # Call the self.on_response callback function when we receive a message from the workers\n",
    "        await self.callback_queue.consume(self.on_get_workers_response)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # We will run this callback function when we recevie messages from the workers\n",
    "    \n",
    "    async def add_new_queues(self):\n",
    "        for queue_name in self.w2s_queue_names:\n",
    "            print(f'adding {queue_name} queue')\n",
    "            task_queue_w2s = await self.channel.declare_queue(queue_name,durable=True)\n",
    "            await task_queue_w2s.bind(self.exchange, routing_key=queue_name)\n",
    "            await task_queue_w2s.consume(self.on_data2workers_response)\n",
    "            print('*** DONE ***')\n",
    "            \n",
    "    async def on_get_workers_response(self, message: IncomingMessage):\n",
    "        \n",
    "        print('\\n ---- SERVER ON_RESPONSE STARTS ----')\n",
    "        print('message arrived back from worker: ' + str(message.body))\n",
    "        print('correlation id of the incoming message: '+message.correlation_id)        \n",
    "        \n",
    "        self.num_on_response_calls = self.num_on_response_calls+1\n",
    "        print('self.num_on_response_calls:', self.num_on_response_calls)\n",
    "        \n",
    "        json_loads=json.loads(str(message.body.decode()))       \n",
    "        orig_routing =  json_loads[\"orig_routing\"] \n",
    "        print('orig_routing:', orig_routing)\n",
    "       \n",
    "        worker_name=json_loads[\"worker_name\"]\n",
    "        self.set_of_workers.add(worker_name)\n",
    "         \n",
    "        queue_name = worker_name+'_data_w2s'\n",
    "        print('new queue name:', queue_name)\n",
    "        self.w2s_queue_names.append(queue_name)\n",
    "        \n",
    "        if self.num_on_response_calls == self.num_of_workers:\n",
    "            print('** All messages we needed arrived **')\n",
    "            future = self.futures.pop(message.correlation_id)\n",
    "            future.set_result(self.set_of_workers)\n",
    "            print(f'future object is done: {future}')  \n",
    "        \n",
    "        else:\n",
    "            print(f'*** NOT ENOUGH WORKERS YET: {self.num_on_response_calls} ***')\n",
    "            \n",
    "            #future = self.futures.pop(message.correlation_id)\n",
    "            #future.set_result(message.body)\n",
    "            #print(f'future object is done: {future}')\n",
    "            \n",
    "        print('---- SERVER ON_RESPONSE ENDS ---- \\n')\n",
    "\n",
    "   \n",
    "    def on_data2workers_response(self, message: IncomingMessage):\n",
    "        \n",
    "        print('\\n ---- SERVER ON_DATA RESPONSE STARTS ----')\n",
    "        print('message arrived back from worker: ' + str(message.body))\n",
    "        print('correlation id of the incoming message: '+message.correlation_id)        \n",
    "        \n",
    "        self.num_on_data2workers_calls = self.num_on_data2workers_calls+1\n",
    "        \n",
    "        json_loads=json.loads(str(message.body.decode()))       \n",
    "        orig_routing =  json_loads[\"orig_routing\"] \n",
    "        print('orig_routing', orig_routing)\n",
    "        \n",
    "        future = self.datafutures.pop(message.correlation_id)\n",
    "        future.set_result('DATA SUCCESS')\n",
    "            \n",
    "        \n",
    "        if self.num_on_data2workers_calls == self.num_of_workers:\n",
    "            print('** All messages we needed for data transfer arrived **')\n",
    "            #future = self.datafutures.pop(message.correlation_id)\n",
    "            #future.set_result(self.set_of_workers)\n",
    "            #print(f'future object is done: {future}')\n",
    "            \n",
    "        \n",
    "            \n",
    "        print('---- SERVER ON_DATA RESPONSE ENDS ---- \\n')\n",
    "        \n",
    "    async def send_data2workers(self,data):\n",
    "        print('sending data to workers!')\n",
    "        \n",
    "        correlation_id = str(uuid.uuid4())\n",
    "        future = loop.create_future()\n",
    "        self.datafutures[correlation_id] = future\n",
    "        \n",
    "        list_of_workers=list(self.set_of_workers)\n",
    "        myrouting=list_of_workers[0]+'_data_s2w'\n",
    "        reply_to_queue = list_of_workers[0]+'_data_w2s'\n",
    "        \n",
    "        message_body = \"Data sent to\"+\"_\"+myrouting\n",
    "        print(myrouting)\n",
    "        \n",
    "        # Below we send a message to the workers.\n",
    "        # We also send the correlation_id of the message,\n",
    "        # and the name of the callback_queue \n",
    "        # where we expect to recevie the answer from the workers received who received our message\n",
    "        \n",
    "        await self.exchange.publish(\n",
    "                Message(\n",
    "                    message_body.encode(),\n",
    "                    content_type='text/plain',\n",
    "                    correlation_id=correlation_id,\n",
    "                    reply_to=reply_to_queue,\n",
    "                    #delivery_mode=DeliveryMode.PERSISTENT\n",
    "                ),\n",
    "                routing_key=myrouting,\n",
    "            )\n",
    "        \n",
    "        # bind the callback_queue with its routing_key to the exchange\n",
    "        #await self.callback_queue.bind(self.exchange, routing_key=self.callback_queue.name)\n",
    "        \n",
    "    async def get_workers_list(self):\n",
    "        correlation_id = str(uuid.uuid4())\n",
    "        \n",
    "        #Create an asyncio.Future object attached to the event loop.\n",
    "        #This future object will contain the result received from the worker\n",
    "        future = loop.create_future()\n",
    "\n",
    "        # Add new key-value pairs to the self.futures dictionary\n",
    "        self.futures[correlation_id] = future\n",
    "\n",
    "        #index=np.random.randint(0,3)\n",
    "        #routing_list=['Pittsburgh','NYC','Washington']\n",
    "        myrouting='get_workers'\n",
    "        #myrouting='Pittsburgh'\n",
    "        \n",
    "        message_body = \"Message\"+\"_\"+myrouting\n",
    "        print(myrouting)\n",
    "        \n",
    "        # Below we send a message to the workers.\n",
    "        # We also send the correlation_id of the message,\n",
    "        # and the name of the callback_queue \n",
    "        # where we expect to recevie the answer from the workers received who received our message\n",
    "        \n",
    "        await self.exchange.publish(\n",
    "                Message(\n",
    "                    message_body.encode(),\n",
    "                    content_type='text/plain',\n",
    "                    correlation_id=correlation_id,\n",
    "                    reply_to=self.callback_queue.name,\n",
    "                    #delivery_mode=DeliveryMode.PERSISTENT\n",
    "                ),\n",
    "                routing_key=myrouting,\n",
    "            )\n",
    "        \n",
    "        # bind the callback_queue with its routing_key to the exchange\n",
    "        await self.callback_queue.bind(self.exchange, routing_key=self.callback_queue.name)\n",
    "        \n",
    "        print('************')\n",
    "        \n",
    "        \n",
    "        return str(await future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main_func(num_of_workers,loop):\n",
    "    my_rpc = RpcClient(num_of_workers,loop)\n",
    "    await my_rpc.connect()\n",
    "    response = await my_rpc.get_workers_list()\n",
    "    \n",
    "    print(\" [.] Got:\" +response)\n",
    "    \n",
    "    await my_rpc.add_new_queues()\n",
    "    \n",
    "    #print('*** Distribute Data to Workers ***')\n",
    "    #await my_rpc.send_data2workers('DATA')\n",
    "    return my_rpc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_workers\n",
      "************\n",
      "\n",
      " ---- SERVER ON_RESPONSE STARTS ----\n",
      "message arrived back from worker: b'{\"request\": \"Message_get_workers\", \"orig_routing\": \"get_workers\", \"worker_name\": \"w_172.31.21.156_27898\", \"curr_time\": \"1643517255.1179123\"}'\n",
      "correlation id of the incoming message: 5cf0dd3f-3d81-4189-8a01-b8d7e1369f4f\n",
      "self.num_on_response_calls: 1\n",
      "orig_routing: get_workers\n",
      "new queue name: w_172.31.21.156_27898_data_w2s\n",
      "*** NOT ENOUGH WORKERS YET: 1 ***\n",
      "---- SERVER ON_RESPONSE ENDS ---- \n",
      "\n",
      "\n",
      " ---- SERVER ON_RESPONSE STARTS ----\n",
      "message arrived back from worker: b'{\"request\": \"Message_get_workers\", \"orig_routing\": \"get_workers\", \"worker_name\": \"w_172.31.21.156_27626\", \"curr_time\": \"1643517255.121956\"}'\n",
      "correlation id of the incoming message: 5cf0dd3f-3d81-4189-8a01-b8d7e1369f4f\n",
      "self.num_on_response_calls: 2\n",
      "orig_routing: get_workers\n",
      "new queue name: w_172.31.21.156_27626_data_w2s\n",
      "** All messages we needed arrived **\n",
      "future object is done: <Future finished result={'w_172.31.21.156_27626', 'w_172.31.21.156_27898'}>\n",
      "---- SERVER ON_RESPONSE ENDS ---- \n",
      "\n",
      " [.] Got:{'w_172.31.21.156_27898', 'w_172.31.21.156_27626'}\n",
      "adding w_172.31.21.156_27898_data_w2s queue\n",
      "*** DONE ***\n",
      "adding w_172.31.21.156_27626_data_w2s queue\n",
      "*** DONE ***\n"
     ]
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "my_rpc=loop.run_until_complete(main_func(num_of_workers,loop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w_172.31.21.156_27898_data_w2s', 'w_172.31.21.156_27626_data_w2s']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_rpc.w2s_queue_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending data to workers!\n",
      "w_172.31.21.156_27898_data_s2w\n",
      "\n",
      " ---- SERVER ON_DATA RESPONSE STARTS ----\n",
      "message arrived back from worker: b'{\"results\": \"EM success\", \"orig_routing\": \"w_172.31.21.156_27898_data_s2w\", \"worker_name\": \"w_172.31.21.156_27898\"}'\n",
      "correlation id of the incoming message: ae8052e6-de74-409a-810b-a6db70a0d109\n",
      "orig_routing w_172.31.21.156_27898_data_s2w\n",
      "---- SERVER ON_DATA RESPONSE ENDS ---- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    \n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(my_rpc.send_data2workers('DATA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    my_rpc.num_on_response_calls=0\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(my_rpc.get_workers_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping node 'rabbit@ip-172-31-21-156' ...\n",
      "Resetting node 'rabbit@ip-172-31-21-156' ...\n",
      "Starting node 'rabbit@ip-172-31-21-156' ...\n"
     ]
    }
   ],
   "source": [
    "# Let's reset the rabbitmq\n",
    "!sudo rabbitmqctl stop_app\n",
    "!sudo rabbitmqctl reset\n",
    "!sudo rabbitmqctl start_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing bindings ...\r\n"
     ]
    }
   ],
   "source": [
    "!sudo rabbitmqctl list_bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
