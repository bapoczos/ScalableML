{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade celery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating user \"myguest\" ...\n",
      "Error: user_already_exists: myguest\n",
      "Setting permissions for user \"myguest\" in vhost \"/\" ...\n"
     ]
    }
   ],
   "source": [
    "!sudo rabbitmqctl add_user myguest myguestpwd\n",
    "!sudo rabbitmqctl set_permissions -p / myguest \".\" \".\" \".*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing users ...\r\n",
      "guest\t[administrator]\r\n",
      "myguest\t[]\r\n"
     ]
    }
   ],
   "source": [
    "!sudo rabbitmqctl list_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will run on the **server** machine. It will **ask its worker machines** to complete some sorting tasks and send the results back to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from celery import group\n",
    "from mergesort_worker import sort, merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of some elements in random order.\n",
    "sequence = list(range(800000))\n",
    "random.shuffle(sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the sequence in a number of chunks and process those independently.\n",
    "n = 4\n",
    "l = len(sequence) // n\n",
    "subseqs = [sequence[i * l:(i + 1) * l] for i in range(n - 1)]\n",
    "subseqs.append(sequence[(n - 1) * l:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subseqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lentght of sequence 0: 200000\n",
      "Lentght of sequence 1: 200000\n",
      "Lentght of sequence 2: 200000\n",
      "Lentght of sequence 3: 200000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(subseqs)):\n",
    "    print('Lentght of sequence {}: {}'.format(i,len(subseqs[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you run the next cell, you will need to run th code on your worker machines with**\n",
    "\n",
    "Use three or four workers.\n",
    "\n",
    "**\"celery -A mergesort_worker worker --loglevel=info\"** <br>\n",
    "or with a concurency number, e.g **\"celery -A mergesort_worker worker --loglevel=info --concurrency=3\"**\n",
    "\n",
    "Then that machine will become a worker, and will be able to run the app task, i.e. the sort function, whenever the broker requests it.\n",
    "\n",
    "**The below results will depend on your instance types and internet speed between the machines and rabbitMQ server.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks sent to workers in 0.98s\n",
      "Results from all the workers came back in 6.60s\n",
      "Distributed mergesort took 7.06s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Ask the Celery workers to sort each sub-sequence.\n",
    "# Use a group to run the individual independent tasks as a unit of work.\n",
    "\n",
    "# celery.group creates a group of tasks to be executed in parallel.\n",
    "# 'sort.s' is the signature of the sort function. This indicates that we want to call this function on the worker machines\n",
    "# The group(fun.s) will run the function fun parallel on the worker machines\n",
    "\n",
    "lazy_partials = group(sort.s(seq) for seq in subseqs)() # call remote workers to run the sort task parallel \n",
    "t1 = time.time()-t0\n",
    "\n",
    "# We will wait till we get back all results from the workers\n",
    "partials = lazy_partials.get() # will wait for the tasks to return\n",
    "\n",
    "t2 = time.time()-t0\n",
    "\n",
    "# Merge all the individual sorted sub-lists into our final result.\n",
    "result = partials[0]\n",
    "for partial in partials[1:]:\n",
    "    result = merge(result, partial) # local merge the results back from the workers\n",
    "\n",
    "t3 = time.time() - t0\n",
    "\n",
    "print('Tasks sent to workers in %.02fs' % (t1))\n",
    "print('Results from all the workers came back in %.02fs' % (t2))\n",
    "print('Distributed mergesort took %.02fs' % (t3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local mergesort took 18.08s\n"
     ]
    }
   ],
   "source": [
    "# Do the same thing locally and compare the times.\n",
    "t0 = time.time()\n",
    "\n",
    "# Here we will call the 'sort' function witohut its signature 'sort.s' to indicate we want to run this locally.\n",
    "truth = sort(sequence)\n",
    "dt = time.time() - t0\n",
    "print('Local mergesort took %.02fs' % (dt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this case local sort took longer time then parralel sort using the workers!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final sanity checks.\n",
    "assert result == truth\n",
    "assert result == sorted(sequence)\n",
    "\n",
    "# Yayyy sorting was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us see some more tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "iter 0: d518d820-2415-427d-876b-45c21caeaba2\n",
      "iter 1: bf1bab34-b5e1-45c3-a602-f8a531c125ed\n",
      "iter 2: 817f306c-c25a-4223-b897-79dcb6f35f56\n",
      "iter 3: d21df6f3-34ae-4804-a263-2dcbff5fa2da\n"
     ]
    }
   ],
   "source": [
    "# The below line just sends the tasks to the workers and ask them to run the tasks parallel on the worker machines.\n",
    "# The group command make it possible to run these tasks parallel and put the results into the 'lazy_partials' variable.\n",
    "lazy_partials = group(sort.s(seq) for seq in subseqs)() # call remote workers to run the sort task parallel \n",
    "\n",
    "print(len(lazy_partials))\n",
    "for it, val in enumerate(lazy_partials): \n",
    "    print(f'iter {it}: {val}')\n",
    "\n",
    "# We get the results back in a lazy way. The results have not been calculated yet!   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# We broke our dataset to 4 parts, that is why we see 4 distributed tasks.\n",
    "print(len(subseqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "length of chunk 0: 200000\n",
      "length of chunk 1: 200000\n",
      "length of chunk 2: 200000\n",
      "length of chunk 3: 200000\n"
     ]
    }
   ],
   "source": [
    "# We need to call the .get() function to get the final results from all the workers:\n",
    "partials = lazy_partials.get()   \n",
    "\n",
    "print(len(partials))\n",
    "for i in range(len(partials)): \n",
    "    print(f'length of chunk {i}: {len(partials[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us check the running time again!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " took 0.72s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "lazy_partials = group(sort.s(seq) for seq in subseqs)() # call remote workers to run the sort task \n",
    "dt = time.time() - t0\n",
    "print(' took %.02fs' % (dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took this much time to communicate with the workes, but the results are not calculated yet.\n",
    "In the background calculation continues..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 4.45s to get the results back\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "partials = lazy_partials.get() # will wait for the tasks to return\n",
    "dt = time.time() - t0\n",
    "print('took %.02fs to get the results back' % (dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We needed this much more time to get all the calculated results from the workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
